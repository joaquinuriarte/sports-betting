{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4165ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Create, Train, and Predict Baseline Models\n",
    "\n",
    "# Logistic Regressor\n",
    "# Random Forest Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b68658b",
   "metadata": {},
   "source": [
    "Import All Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "251a0e8a-b944-4323-8731-207322906548",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Manually add the project root to sys.path\n",
    "sys.path.append('/Users/joaquinuriarte/Documents/GitHub/sports-betting/')\n",
    "\n",
    "# === STEP 0: Imports\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from modules.data_structures.model_dataset import ModelDataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from model_binaries.utils.binary_utils import save_entity, load_entity, cross_val_train, compute_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1c2254",
   "metadata": {},
   "source": [
    "Load Train into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce64e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to load train, test, and val datasets\n",
    "train_test_val_folder_path = \"/Users/joaquinuriarte/Documents/GitHub/sports-betting/processed_datasets/model_v0/scaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a23c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_entity(train_test_val_folder_path, \"scaled_train.pkl\")\n",
    "train_dataset = load_entity(train_test_val_folder_path, \"scaled_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff0899",
   "metadata": {},
   "source": [
    "Define Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f62ddf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(dataset, label_key: str = \"label\") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts feature vectors (X) and labels (y) from ModelDataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset (ModelDataset): Your custom dataset containing examples.\n",
    "        label_key (str): The name of the key used for your labels within features.\n",
    "    \n",
    "    Returns:\n",
    "        X (np.ndarray): 2D array of shape (num_examples, num_features).\n",
    "        y (np.ndarray): 1D array of shape (num_examples,).\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for example in dataset.examples:\n",
    "        # example.features is a dict: { feature_name: [list_of_values] }\n",
    "        # We assume \"label\" is a single-value list for y; \n",
    "        # e.g. { \"label\": [1], \"PTS\": [10.3], \"AST\": [5.2], ... }\n",
    "        \n",
    "        # 1) Extract label\n",
    "        y_value = example.features[label_key][0]  # e.g. [1] -> 1\n",
    "        y_list.append(y_value)\n",
    "        \n",
    "        # 2) Extract numeric fields for X. You can decide which keys to skip, \n",
    "        #    or you can store them in a certain order.\n",
    "        feature_vec = []\n",
    "        for k, v in example.features.items():\n",
    "            if k == label_key:\n",
    "                continue\n",
    "            # v is a list of numeric values or a single numeric value\n",
    "            # Flatten or pick the first if each feature is stored as [value]\n",
    "            # Make sure they are floats or ints\n",
    "            feature_vec.extend(v)  \n",
    "        \n",
    "        X_list.append(feature_vec)\n",
    "    \n",
    "    X = np.array(X_list, dtype=np.float32)\n",
    "    y = np.array(y_list, dtype=np.float32)\n",
    "    return X, y\n",
    "\n",
    "def tune_logistic_regression(X, y):\n",
    "    \"\"\"\n",
    "    Perform Randomized Search for Logistic Regression hyperparameters.\n",
    "    Returns the best estimator and a summary of the results.\n",
    "    \"\"\"\n",
    "    # Define the model\n",
    "    log_reg = LogisticRegression(max_iter=10000)  # 'liblinear' often works well for small/medium datasets\n",
    "    \n",
    "    # Hyperparameter distributions to sample from\n",
    "    param_dist = {\n",
    "        \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        \"solver\": [\"liblinear\", \"saga\"],\n",
    "        \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"l1_ratio\": [0.0, 0.5, 1.0],  # only used if penalty='elasticnet'\n",
    "        \"class_weight\": [None, \"balanced\"]\n",
    "    }\n",
    "    \n",
    "    # Create a stratified K-fold for balanced CV splits\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=log_reg,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=5,                # number of parameter settings to try\n",
    "        scoring={\"f1\": \"f1\", \"precision\": \"precision\", \"recall\": \"recall\", \"roc_auc\": \"roc_auc\"},            # or use multiple metrics (see below)\n",
    "        refit=\"f1\",\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X, y)\n",
    "    \n",
    "    best_estimator = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "    best_score = random_search.best_score_\n",
    "    \n",
    "    return best_estimator, best_params, best_score\n",
    "\n",
    "def tune_logistic_regression_with_poly(X, y):\n",
    "    pipe = Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(include_bias=False)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "    param_dist = {\n",
    "        \"poly__degree\": [1, 2],   # search polynomial degrees\n",
    "        \"logreg__solver\": [\"liblinear\", \"saga\"],\n",
    "        \"logreg__penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"logreg__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        \"logreg__l1_ratio\": [0.0, 0.5, 1.0],  # only relevant if penalty='elasticnet'\n",
    "        \"logreg__class_weight\": [None, \"balanced\"]\n",
    "    }\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # For multiple metrics\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=15,\n",
    "        scoring={\"f1\": \"f1\", \"precision\": \"precision\", \"recall\": \"recall\", \"roc_auc\": \"roc_auc\"},\n",
    "        refit=\"f1\",\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    search.fit(X, y)\n",
    "    \n",
    "    best_estimator = search.best_estimator_        # Pipeline with best-found hyperparams\n",
    "    best_params = search.best_params_\n",
    "    best_score = search.best_score_               # best CV 'f1' score\n",
    "    return best_estimator, best_params, best_score\n",
    "\n",
    "def tune_random_forest(X, y):\n",
    "    \"\"\"\n",
    "    Perform Randomized Search for Random Forest hyperparameters.\n",
    "    Returns the best estimator and a summary of the results.\n",
    "    \"\"\"\n",
    "    # Define the model\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    # Hyperparameter distributions to sample from\n",
    "    param_dist = {\n",
    "        'n_estimators': [50, 100, 200, 300, 500],\n",
    "        'max_depth': [None, 5, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'bootstrap': [True, False],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "    }\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,             \n",
    "        scoring = {\n",
    "            \"f1\": \"f1\",\n",
    "            \"recall\": \"recall\",\n",
    "            \"precision\": \"precision\",\n",
    "            \"roc_auc\": \"roc_auc\"\n",
    "        },           # or use multiple metrics\n",
    "        refit=\"f1\",\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X, y)\n",
    "    \n",
    "    best_estimator = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "    best_score = random_search.best_score_\n",
    "    \n",
    "    return best_estimator, best_params, best_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Computes standard classification metrics for the model on given test data.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # For AUC, you need predicted probabilities for the positive class\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "    \n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall:\", rec)\n",
    "    print(\"F1:\", f1)\n",
    "    if auc is not None:\n",
    "        print(\"AUC:\", auc)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"auc\": auc\n",
    "    }\n",
    "\n",
    "def find_optimal_threshold(y_true, y_prob, num_thresholds=101):\n",
    "    \"\"\"\n",
    "    Finds the threshold between 0 and 1 that yields the maximum F1 score\n",
    "    when converting predicted probabilities to binary predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): Ground-truth labels (0 or 1).\n",
    "        y_prob (array-like): Predicted probabilities for the positive class.\n",
    "        num_thresholds (int): Number of thresholds to check from 0.0 to 1.0 (inclusive).\n",
    "\n",
    "    Returns:\n",
    "        best_threshold (float): The threshold that yields the highest F1 score.\n",
    "        best_f1 (float): The best F1 score obtained at that threshold.\n",
    "    \"\"\"\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0.0\n",
    "    \n",
    "    # Generate equally spaced thresholds from 0 to 1\n",
    "    thresholds = np.linspace(0, 1, num_thresholds)\n",
    "    \n",
    "    for t in thresholds:\n",
    "        y_pred_custom = (y_prob >= t).astype(int)\n",
    "        score = f1_score(y_true, y_pred_custom)\n",
    "        if score > best_f1:\n",
    "            best_f1 = score\n",
    "            best_threshold = t\n",
    "    \n",
    "    return best_threshold, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae490a02",
   "metadata": {},
   "source": [
    "Train & Evaluate Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ae74a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Params: {'solver': 'saga', 'penalty': 'l2', 'l1_ratio': 1.0, 'class_weight': None, 'C': 0.001}\n",
      "Best CV F1: 0.7328354899465991\n",
      "Logistic Regression performance on test set:\n",
      "Accuracy: 0.5783274440518257\n",
      "Precision: 0.5783274440518257\n",
      "Recall: 1.0\n",
      "F1: 0.7328358208955223\n",
      "AUC: 0.6296957905236529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaquinuriarte/Documents/GitHub/sports-betting/sports-betting/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5783274440518257,\n",
       " 'precision': 0.5783274440518257,\n",
       " 'recall': 1.0,\n",
       " 'f1': 0.7328358208955223,\n",
       " 'auc': 0.6296957905236529}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get your X, y from the dataset\n",
    "X_train, y_train = get_features_and_labels(train_dataset, label_key=\"Team_A_Wins\")\n",
    "X_test, y_test = get_features_and_labels(train_dataset, label_key=\"Team_A_Wins\")\n",
    "\n",
    "# Tune Logistic Regression\n",
    "best_lr, lr_params, lr_score = tune_logistic_regression(X_train, y_train)\n",
    "print(\"Best Logistic Regression Params:\", lr_params)\n",
    "print(\"Best CV F1:\", lr_score)\n",
    "\n",
    "# Evaluate on test\n",
    "print(\"Logistic Regression performance on test set:\")\n",
    "evaluate_model(best_lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867ce79",
   "metadata": {},
   "source": [
    "Train & Evaluate a Polynomial (2) Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e202350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your X, y from the dataset\n",
    "X_train, y_train = get_features_and_labels(train_dataset, label_key=\"Team_A_Wins\")\n",
    "X_test, y_test = get_features_and_labels(train_dataset, label_key=\"Team_A_Wins\")\n",
    "\n",
    "# Tune Logistic Regression\n",
    "best_lr, lr_params, lr_score = tune_logistic_regression_with_poly(X_train, y_train)\n",
    "print(\"Best Logistic Regression Params:\", lr_params)\n",
    "print(\"Best CV F1:\", lr_score)\n",
    "\n",
    "# Evaluate on test\n",
    "print(\"Logistic Regression performance on test set:\")\n",
    "evaluate_model(best_lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "733c7012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.560, Best F1: 0.7333\n"
     ]
    }
   ],
   "source": [
    "y_prob = best_lr.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "# Call our threshold tuning function\n",
    "optimal_thresh, optimal_f1 = find_optimal_threshold(y_test, y_prob, num_thresholds=101)\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_thresh:.3f}, Best F1: {optimal_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f863089",
   "metadata": {},
   "source": [
    "Train & Evaluate Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe2004d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Random Forest Params: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 5, 'criterion': 'entropy', 'class_weight': None, 'bootstrap': True}\n",
      "Best CV F1: 0.7275076000757503\n",
      "Random Forest performance on test set:\n",
      "Accuracy: 0.6183745583038869\n",
      "Precision: 0.6027060270602707\n",
      "Recall: 0.9979633401221996\n",
      "F1: 0.7515337423312884\n",
      "AUC: 0.8601841211325902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6183745583038869,\n",
       " 'precision': 0.6027060270602707,\n",
       " 'recall': 0.9979633401221996,\n",
       " 'f1': 0.7515337423312884,\n",
       " 'auc': 0.8601841211325902}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get your X, y from the dataset\n",
    "X_train, y_train = get_features_and_labels(train_dataset, label_key=\"Team_A_Wins\")\n",
    "X_test, y_test = get_features_and_labels(train_dataset, label_key=\"Team_A_Wins\")\n",
    "\n",
    "# Tune Random Forest\n",
    "best_rf, rf_params, rf_score = tune_random_forest(X_train, y_train)\n",
    "print(\"Best Random Forest Params:\", rf_params)\n",
    "print(\"Best CV F1:\", rf_score)\n",
    "\n",
    "# Evaluate on test\n",
    "print(\"Random Forest performance on test set:\")\n",
    "evaluate_model(best_rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a9e3158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.560, Best F1: 0.7333\n"
     ]
    }
   ],
   "source": [
    "y_prob = best_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Call our threshold tuning function\n",
    "optimal_thresh, optimal_f1 = find_optimal_threshold(y_test, y_prob, num_thresholds=101)\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_thresh:.3f}, Best F1: {optimal_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('sports-betting': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "42d1e72f09edad5b8341e1a78b673e0aa6929e61770b700654f70887e86e86ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
